{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(files, v_tag, t_tags, extract_func, drop):\n",
    "    df = []\n",
    "    for exp_path in files:\n",
    "        # load config.json\n",
    "        cfg_path = os.path.dirname(exp_path) + '/1/config.json'\n",
    "        f = open(cfg_path)\n",
    "        cfg = json.load(f)\n",
    "        f.close()\n",
    "\n",
    "        # extract config\n",
    "        cfg_dict = {}\n",
    "        cfg_dict.update(cfg['train_cfg'])\n",
    "        cfg_dict.update(cfg['meta_cfg'])\n",
    "\n",
    "        # load run.json\n",
    "        run_path = os.path.dirname(exp_path) + '/1/run.json'\n",
    "        f = open(run_path)\n",
    "        run = json.load(f)\n",
    "        f.close()\n",
    "        if run['status'] != \"COMPLETED\":\n",
    "            print(cfg_path)\n",
    "            continue\n",
    "\n",
    "        # extract model name\n",
    "        if (cfg_dict['model'] == 'DAN_sim' or cfg_dict['model'] == 'DAN_alt') and cfg_dict['alpha'] == 0:\n",
    "            cfg_dict['model'] = 'CNN'\n",
    "        elif cfg_dict['model'] in ['DAN_sim', 'DAN_alt']:\n",
    "            cfg_dict['model'] = 'DAN'\n",
    "        elif cfg_dict['model'] == 'AFLAC'  and cfg_dict['p_d'] == 'dependent_y':\n",
    "            pass\n",
    "        elif cfg_dict['model'] == 'AFLAC':\n",
    "            cfg_dict['model'] = 'AFLAC-Abl'\n",
    "        elif cfg_dict['model'] == 'CIDDG':\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # extract scores\n",
    "        event = EventAccumulator(exp_path)\n",
    "        event.Reload()\n",
    "        if v_tag in event.Tags()['scalars']:\n",
    "            # add validation\n",
    "            w_times, step_nums, vals = zip(*event.Scalars(v_tag))\n",
    "            cfg_dict[v_tag] = max(vals) * 100\n",
    "            idx_by_vtag = np.argmax(vals)\n",
    "\n",
    "            # add scores\n",
    "            cfg_dict = extract_func(event, cfg_dict, v_tag, t_tags, idx_by_vtag)\n",
    "        df.append(cfg_dict)\n",
    "\n",
    "    df = pd.io.json.json_normalize(df)\n",
    "    df = df.fillna('NA')\n",
    "    drop = list(set(df.columns) & set(drop))\n",
    "    df = df.drop(drop, axis=1)\n",
    "    return df\n",
    "\n",
    "def summary(df, v_tag, t_tags):\n",
    "    tags_tv = t_tags + [v_tag]\n",
    "    tags_tv = list(set(tags_tv))\n",
    "    groupby = list(df.columns.drop(tags_tv + ['seed']))\n",
    "    df[tags_tv] = df[tags_tv].astype(np.float)\n",
    "    summary = df.groupby(groupby)[tags_tv].agg([np.mean, 'sem']).sort_values((v_tag, 'mean'), ascending=False)\n",
    "    summary = summary.reset_index().drop_duplicates(subset=['model'])\n",
    "    return summary\n",
    "\n",
    "\n",
    "def extract_by_validation(event, cfg_dict, v_tag, t_tags, idx):\n",
    "    for t_tag in t_tags:\n",
    "        w_times, step_nums, vals = zip(*event.Scalars(t_tag))\n",
    "        cfg_dict[t_tag] = vals[idx] * 100\n",
    "    return cfg_dict\n",
    "\n",
    "\n",
    "def result(df_sum, v_tag, t_name):\n",
    "    df_sum = df_sum.set_index('model').drop(['alpha', v_tag], axis=1).round(1)\n",
    "    df_sum = df_sum.reindex(['CNN', 'DAN', 'CIDDG', 'AFLAC-Abl', 'AFLAC'])\n",
    "    df_sum = df_sum.T.reset_index().T\n",
    "    df_sum.columns = df_sum.loc['level_1']\n",
    "    df_sum =  df_sum.drop(['level_0', 'level_1'])\n",
    "    df_sum = df_sum.groupby([t_name, t_name], axis=1).apply(lambda x: x.astype(str).apply('±'.join, 1)).T\n",
    "    df_sum.columns.name = ''\n",
    "    df_sum.index.name = 'Target'\n",
    "    return df_sum\n",
    "\n",
    "def aggregate(results):\n",
    "    df_result = pd.concat(results)\n",
    "    df_result_ = df_result.applymap(lambda x: x.split('±')[0]).copy()\n",
    "    df_result_ = df_result_.astype(float)\n",
    "    df_result.loc['Avg'] = df_result_.mean(axis=0).round(1)\n",
    "    return df_result\n",
    "\n",
    "drop = ['batch_size', 'lr', 'dataset_class.py/type', 'dataset_name', 'n_iter', 'train.py/function', \n",
    "        'validation', 'alpha_scheduler', 'lr_scheduler', 'biased', 'weight_decay', 'gpu', \n",
    "        'num_train_d', 'n_checks', 'test_key', 'p_d', 'num_train_e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "keys = ['0', '15', '30', '45', '60', '75']\n",
    "for key in keys:\n",
    "    files = glob('logs/MNISTR'+key+'1_BM/*/*events*')\n",
    "    tags = ['MNISTR_'+key]\n",
    "    v_tag = 'MNISTR_'+key+'_y_acc_valid'\n",
    "    t_tags =  ['MNISTR_'+key+'_y_acc_test']\n",
    "    df = create_df(files, v_tag, t_tags, extract_by_validation, drop)\n",
    "    df_sum = summary(df, v_tag, t_tags)\n",
    "    results.append(result(df_sum, v_tag, 'M' + key))\n",
    "\n",
    "df_result = aggregate(results)\n",
    "df_result['Dataset'] = 'BMNISTR-1'\n",
    "bmnistr1 = df_result.reset_index().set_index(['Dataset', 'Target'])\n",
    "bmnistr1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
